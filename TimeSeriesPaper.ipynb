{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TimeSeriesPaper.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPZghdfpBY7ao3yRBBaCk20",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NUELBUNDI/PDS_PROJECT/blob/main/TimeSeriesPaper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0VhdJmWoHAZ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh import models, palettes, transform\n",
        "from bokeh.plotting import figure, show\n",
        "import pandas as pd\n",
        "import pandas_profiling\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn import cluster, decomposition, pipeline, preprocessing\n",
        "import statsmodels\n",
        "import missingno as mn\n",
        "import plotly.offline as pyo\n",
        "import plotly.express as px\n",
        "import datetime\n",
        "import plotly.graph_objects as go\n",
        "from statsmodels.tsa.stattools import adfuller,acf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf ,plot_pacf\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "# import pmdarima as pm\n",
        "import statsmodels.api as sm\n",
        "from pylab import rcParams\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read The Pd\n",
        "\n",
        "df=pd.read_csv('https://raw.githubusercontent.com/NUELBUNDI/PDS_PROJECT/main/SalesPerMonthWst.csv')\n",
        "# df=pd.read_csv(\"https://raw.githubusercontent.com/NUELBUNDI/PDS_PROJECT/main/climate.csv\")\n",
        "df.columns=['date','sales']\n",
        "df.head(1)"
      ],
      "metadata": {
        "id": "Se9Wj5rpq4Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# airline = pd.read_csv('AirPassengers.csv',\n",
        "#                        index_col ='Month',\n",
        "#                        parse_dates = True)\n",
        "# train ,test = df[155:189] , df[190:]"
      ],
      "metadata": {
        "id": "j0DnL69PA_mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date']=pd.to_datetime(df['date'])\n",
        "df.reset_index()\n",
        "df=df.set_index('date')\n",
        "ts=df['sales']\n",
        "ts.head()\n"
      ],
      "metadata": {
        "id": "N0IY5xpHy3_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Train and Test Data\n",
        "\n",
        "train_data=ts['2010-01-02':'2020-01-01']\n",
        "\n",
        "test_data=ts['2020-01-02':'2021-01-11']"
      ],
      "metadata": {
        "id": "4qmZDQup0BL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize= (10,6))\n",
        "# plt.plot(df)\n",
        "# plt.xlabel('Years')\n",
        "# plt.ylabel('No of Air Passengers')\n",
        "# plt.title('Trend of the Time Series')"
      ],
      "metadata": {
        "id": "TLSiBT2rcZBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.dtypes"
      ],
      "metadata": {
        "id": "rW0-aFZBXfK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.set_style('whitegrid')\n",
        "# plt.figure(figsize=(15,8))\n",
        "# lp=sns.lineplot('date','sales',data=train)\n",
        "# lp.legend(loc='upper right')\n",
        "# plt.title('Monthly Sales',fontsize=20)\n",
        "# plt.xlabel('Month')\n",
        "# # plt.ticklabel_format(style='plain')\n",
        "# plt.ylabel('Sales')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "4jiTZVwnYnF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.plot(figsize=(10,5))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aa4R6eOJ0hTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decomposition=seasonal_decompose(train_data,freq=1)\n",
        "\n",
        "\n",
        "trend=decomposition.trend\n",
        "seasonal=decomposition.seasonal\n",
        "residual=decomposition.resid\n",
        "\n",
        "plt.figure(figsize=(14,8))\n",
        "plt.subplot(411)\n",
        "plt.plot(train_data, label='Original')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(412)\n",
        "plt.plot(trend, label='Trend')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(413)\n",
        "plt.plot(seasonal,label='Seasonality')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(414)\n",
        "plt.plot(residual, label='Residuals')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "Ld8FCKmSv5wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking For Stationarity"
      ],
      "metadata": {
        "id": "HrMVZzix1apm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stationarity_test(timeseries):\n",
        "\n",
        "    # Get rolling statistics for window = 12 i.e. yearly statistics\n",
        "    rolling_mean = timeseries.rolling(window = 12).mean()\n",
        "    rolling_std = timeseries.rolling(window = 12).std()\n",
        "    \n",
        "    # Plot rolling statistic\n",
        "    plt.figure(figsize= (10,6))\n",
        "    plt.xlabel('Years')\n",
        "    plt.ylabel('No of Air Passengers')    \n",
        "    plt.title('Stationary Test: Rolling Mean and Standard Deviation')\n",
        "    plt.plot(timeseries, color= 'blue', label= 'Original')\n",
        "    plt.plot(rolling_mean, color= 'green', label= 'Rolling Mean')\n",
        "    plt.plot(rolling_std, color= 'red', label= 'Rolling Std')   \n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print('Results of Dickey-Fuller Test')\n",
        "    df_test = adfuller(timeseries)\n",
        "    df_output = pd.Series(df_test[0:4], index = ['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
        "    for key, value in df_test[4].items():\n",
        "        df_output['Critical Value (%s)' %key] = value\n",
        "    print(df_output)\n",
        "    print(f'Inference: The time series is {\"non-\" if df_test[1]>=0.05 else \"\"}stationary')\n",
        "\n",
        "stationarity_test(train_data)"
      ],
      "metadata": {
        "id": "sXs98q3n1LDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ADF TEST for stationarity\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "def checks_stationarity(ts_data):\n",
        "    result = adfuller(ts_data)\n",
        "    print('ADF Statistic: %f' % result[0])\n",
        "    print('p-value: %f' % result[1])\n",
        "    print(f'Inference: The time series is {\"non-\" if result[1]>=0.05 else \"\"}stationary')\n",
        "\n",
        "res=checks_stationarity(train_data)\n",
        "res"
      ],
      "metadata": {
        "id": "QFMna53l1TOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make stationary"
      ],
      "metadata": {
        "id": "ME3YABSZ1jVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the First Order Difference\n",
        "train_data_diff=train_data.diff().dropna()\n",
        "\n",
        "stationarity_test(train_data_diff)"
      ],
      "metadata": {
        "id": "_8Ka0f0N22j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Determine P and Q by Plotting the ACF AND PACF\n",
        "\n",
        "def acf_pacf_plot(ts_data):\n",
        "  plot_pacf(ts_data)\n",
        "  plot_acf(ts_data)\n",
        "\n",
        "acf_pacf_plot(train_data_diff)\n",
        "\n"
      ],
      "metadata": {
        "id": "Bauv0gjw38zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AR MODEL"
      ],
      "metadata": {
        "id": "YZWbStmK7rIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ARIMA(train_data, order=(2, 1, 0))  \n",
        "results_AR = model.fit(disp= -1)# If disp < 0 convergence information will not be printed\n",
        "plt.plot(train_data_diff)\n",
        "plt.plot(results_AR.fittedvalues, color='red')\n",
        "plt.title('AR Model, RSS: %.4f'% sum((results_AR.fittedvalues - train_data_diff)**2))"
      ],
      "metadata": {
        "id": "ynH1efF065u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MA MODEL"
      ],
      "metadata": {
        "id": "sn4tkSMU70R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ARIMA(train_data, order=(0, 1, 1))  \n",
        "results_AR = model.fit(disp= -1)# If disp < 0 convergence information will not be printed\n",
        "plt.plot(train_data_diff)\n",
        "plt.plot(results_AR.fittedvalues, color='red')\n",
        "plt.title('MA Model, RSS: %.4f'% sum((results_AR.fittedvalues - train_data_diff)**2))"
      ],
      "metadata": {
        "id": "CCnHEUfm7yBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ARIMA(train_data, order=(2, 1, 2))  \n",
        "results_ARIMA = model.fit(disp=-1)  \n",
        "plt.plot(train_data_diff)\n",
        "plt.plot(results_ARIMA.fittedvalues, color='red')\n",
        "plt.title('Combined Model, RSS: %.4f'% sum((results_ARIMA.fittedvalues-train_data_diff)**2))"
      ],
      "metadata": {
        "id": "dHh6-UMc-KOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\n",
        "\n",
        "print('Total no of predictions: ', len(predictions_diff))\n",
        "predictions_diff.head()"
      ],
      "metadata": {
        "id": "uAsbCb-k8u2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_diff_cumsum = predictions_diff.cumsum()\n",
        "predictions_diff_cumsum.head()"
      ],
      "metadata": {
        "id": "_yWwP28k-l_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "results_ARIMA.plot_predict(start =1, end= 204) "
      ],
      "metadata": {
        "id": "9zoZ_qOl_d3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_values_log_scale = results_ARIMA.forecast(steps = 60)\n",
        "forecast_values_original_scale = np.exp(forecast_values_log_scale[0])\n",
        "\n",
        "forecast_date_range= pd.date_range(\"1961-01-01\", \"1965-12-01\", freq=\"MS\")\n",
        "\n",
        "df_forecast =pd.DataFrame(forecast_values_original_scale, columns=['Forecast'])\n",
        "df_forecast['Month'] = forecast_date_range\n",
        "\n",
        "df_forecast[['Month', 'Forecast']]"
      ],
      "metadata": {
        "id": "DkW2RL3FCI7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN ARIMA MODEL\n",
        "\n",
        "order=(2,1,2)\n",
        "model=ARIMA(endog=train_data,order=order)\n",
        "fit=model.fit()"
      ],
      "metadata": {
        "id": "suL2efR66TyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fit.summary())"
      ],
      "metadata": {
        "id": "lYJ8JyWx7efc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot residual errors\n",
        "\n",
        "residuals = pd.DataFrame(fit.resid)\n",
        "fig, ax = plt.subplots(1,2)\n",
        "residuals.plot(title=\"Residuals\", ax=ax[0])\n",
        "residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9ocdoZ9rRkJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual vs Fitted\n",
        "fit.plot_predict(dynamic=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UFrWMsFPStli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build an ARIMA model manually."
      ],
      "metadata": {
        "id": "cRCyyKJdmgU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#How to do find the optimal ARIMA model manually using Out-of-Time Cross validation\n",
        "\n",
        "# Build Model\n",
        "# model = ARIMA(train, order=(3,2,1))  \n",
        "# order=(2,1,2)\n",
        "# model=ARIMA(endog=train_data,order=order)\n",
        "\n",
        "model=ARIMA(endog=train_data, order=(1, 1, 0))  \n",
        "fitted = model.fit(disp=-1)  \n",
        "\n",
        "# Forecast\n",
        "fc, se, conf = fitted.forecast(22, alpha=0.05)  # 95% conf\n",
        "\n",
        "# Make as pandas series\n",
        "fc_series = pd.Series(fc, index=test_data.index)\n",
        "lower_series = pd.Series(conf[:, 0], index=test_data.index)\n",
        "upper_series = pd.Series(conf[:, 1], index=test_data.index)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12,5), dpi=100)\n",
        "plt.plot(train_data, label='training')\n",
        "plt.plot(test_data, label='actual')\n",
        "plt.plot(fc_series, label='forecast')\n",
        "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
        "                 color='k', alpha=.15)\n",
        "plt.title('Forecast vs Actuals')\n",
        "plt.legend(loc='upper left', fontsize=8)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D8PXAt7MTt2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy metrics\n",
        "def forecast_accuracy(forecast, actual):\n",
        "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
        "    me = np.mean(forecast - actual)             # ME\n",
        "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
        "    mpe = np.mean((forecast - actual)/actual)   # MPE\n",
        "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
        "    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n",
        "    mins = np.amin(np.hstack([forecast[:,None], \n",
        "                              actual[:,None]]), axis=1)\n",
        "    maxs = np.amax(np.hstack([forecast[:,None], \n",
        "                              actual[:,None]]), axis=1)\n",
        "    minmax = 1 - np.mean(mins/maxs)             # minmax\n",
        "    acf1 = acf(fc-test_data)[1]                      # ACF1\n",
        "    return({'MAPE':mape, 'ME':me, 'MAE': mae, \n",
        "            'MPE': mpe, 'RMSE':rmse, 'ACF1':acf1, \n",
        "            'CORR':corr, 'MINMAX':minmax})\n",
        "\n",
        "summary=forecast_accuracy(fc, test_data.values)\n",
        "\n",
        "summary\n"
      ],
      "metadata": {
        "id": "1kfCx4_Ok86z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to do Auto Arima Forecast in Python"
      ],
      "metadata": {
        "id": "e9UuW6LSnJct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import pmdarima as pm\n",
        "\n",
        "model = pm.auto_arima(train_data, start_p=1, start_q=1,\n",
        "                      test='adf',       # use adftest to find optimal 'd'\n",
        "                      max_p=5, max_q=5, # maximum p and q\n",
        "                      m=1,              # frequency of series\n",
        "                      d=None,           # let model determine 'd'\n",
        "                      seasonal=False,   # No Seasonality\n",
        "                      start_P=0, \n",
        "                      D=0, \n",
        "                      trace=True,\n",
        "                      error_action='ignore',  \n",
        "                      suppress_warnings=True, \n",
        "                      stepwise=True)\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "4VuHaXdHmebX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.plot_diagnostics(figsize=(7,5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jzbMVnbrsb0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top left: The residual errors seem to fluctuate around a mean of zero and have a uniform variance.\n",
        "\n",
        "Top Right: The density plot suggest normal distribution with mean zero.\n",
        "\n",
        "Bottom left: All the dots should fall perfectly in line with the red line. Any significant deviations would imply the distribution is skewed.\n",
        "\n",
        "Bottom Right: The Correlogram, aka, ACF plot shows the residual errors are not autocorrelated. Any autocorrelation would imply that there is some pattern in the residual errors which are not explained in the model. So you will need to look for more X’s (predictors) to the model.\n",
        "\n",
        "Overall, it seems to be a good fit. Let’s forecast."
      ],
      "metadata": {
        "id": "iMtb0lSTsl__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "id": "dru_lzvktNZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecast\n",
        "n_periods = 22\n",
        "fc, confint = model.predict(n_periods=n_periods, return_conf_int=True)\n",
        "index_of_fc = np.arange(len(train_data), len(train_data)+n_periods)\n",
        "\n",
        "# make series for plotting purpose\n",
        "fc_series = pd.Series(fc, index=index_of_fc)\n",
        "lower_series = pd.Series(confint[:, 0], index=index_of_fc)\n",
        "upper_series = pd.Series(confint[:, 1], index=index_of_fc)\n",
        "\n",
        "# Plot\n",
        "plt.plot(train_data)\n",
        "plt.plot(fc_series, color='darkgreen')\n",
        "plt.fill_between(lower_series.index, \n",
        "                 lower_series, \n",
        "                 upper_series, \n",
        "                 color='k', alpha=.15)\n",
        "\n",
        "plt.title(\"Final Forecast of WWW Usage\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "M3u4SJYVsphw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.machinelearningplus.com/resources/arima/arima-forecast-test-results/\n",
        "# https://www.machinelearningplus.com/resources/arima/implement-arima-model/\n",
        "# https://www.machinelearningplus.com/time-series/time-series-analysis-python/\n",
        "# https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/\n",
        "# pip install statsmodels==0.11.0\n",
        "# https://www.kaggle.com/satishgunjal/tutorial-time-series-analysis-and-forecasting\n",
        "# https://www.geeksforgeeks.org/python-arima-model-for-time-series-forecasting/"
      ],
      "metadata": {
        "id": "GbPFeUlb_2md"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}