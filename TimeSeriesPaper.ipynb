{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TimeSeriesPaper.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMKjV8e8BfUTuTNANUkFsWo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NUELBUNDI/PDS_PROJECT/blob/main/TimeSeriesPaper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Time Series Project Paper**\n",
        "\n",
        "---\n",
        "## Student Name :Lee Bundi\n",
        "## Student No:  :102586"
      ],
      "metadata": {
        "id": "zef1WYS7w-wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this paper is to model a time series analysis. \n",
        "Time series is a set of observations, each one being recorded at a specific time.\n",
        "Time series analysis is done on a time series data.\n",
        "In this paper our focus will be on univarite time series (Meaning i will use a single set of observation or variable indexed over time).\n",
        "\n",
        "The **basic objective**  is to determine a model that describes the pattern of the time series. Uses for such a model are:\n",
        "\n",
        "1. To describe the important features of the time series pattern.\n",
        "2. To explain how the past affects the future.\n",
        "3. To forecast future values of the series.\n",
        "\n",
        "\n",
        "The time series data i'm using in this paper comprise of annual average temperature in kenya for the period starting 1981 to 2020. The source of the data is https://africaopendata.org/dataset\n"
      ],
      "metadata": {
        "id": "X6FjmI_Rxuwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Steps to Time Series Analysis.\n",
        "\n",
        "\n",
        "*   Visualize the time series plot.\n",
        "*   Check for stationarity.\n",
        "*   Make the time series stationary.\n",
        "*   Plot the ACF and PCF.\n",
        "*   Select the model and train the data.\n",
        "*   Choose the best performing model.\n",
        "*   Forecast using the model choosen on the test data\n",
        "*   Analysis the Forecast performance- iterate through the step until you find the best forecast performance.\n",
        "*   Perform Future forecast.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d7KCp3b72Ezx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Packages\n",
        "\n",
        "%matplotlib inline\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh import models, palettes, transform\n",
        "from bokeh.plotting import figure, show\n",
        "import pandas as pd\n",
        "import pandas_profiling\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn import cluster, decomposition, pipeline, preprocessing\n",
        "import statsmodels\n",
        "import missingno as mn\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "import datetime\n",
        "import plotly.graph_objects as go\n",
        "from statsmodels.tsa.stattools import adfuller,acf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf ,plot_pacf\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import statsmodels.api as sm\n",
        "from pylab import rcParams\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from pmdarima import auto_arima\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n"
      ],
      "metadata": {
        "id": "swr2Re3xw8t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the data set and load it to pandas data frame"
      ],
      "metadata": {
        "id": "y5HeqSu94s7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# df=pd.read_csv('https://raw.githubusercontent.com/NUELBUNDI/PDS_PROJECT/main/SalesPerMonthWst.csv')\n",
        "# df=pd.read_csv(\"https://raw.githubusercontent.com/NUELBUNDI/PDS_PROJECT/main/climate.csv\")\n",
        "df=pd.read_csv(\"https://raw.githubusercontent.com/NUELBUNDI/PDS_PROJECT/main/tempkenyadata.csv\",index_col=0,parse_dates=True)\n",
        "# df.columns=['date','temp']\n",
        "x=df.values\n",
        "# print(x)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Se9Wj5rpq4Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Plot the time series data to visualize and analysis.**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bA9MyqD75l1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(figsize=(12,6))\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Annually Avearage Temperature ')\n",
        "plt.title('Trend of the Time Series')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aa4R6eOJ0hTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decompose a time series.\n",
        "\n",
        "This enable us to visualize the components of time series namely:\n",
        "\n",
        "\n",
        "*   Trend-       Increasing or decreasing value in the series.\n",
        "\n",
        "*   seasonarity- Any repeating cycle\n",
        "*   Noise        Random Variation in the series\n",
        "\n",
        "*   Level       Average value in the series\n",
        "\n"
      ],
      "metadata": {
        "id": "ENn3m4mN58yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "result = seasonal_decompose(df, model='additive')\n",
        "result.plot()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# The series as no seasonality"
      ],
      "metadata": {
        "id": "MvH2g4JP6mqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Checking For Stationarity**"
      ],
      "metadata": {
        "id": "HrMVZzix1apm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check for stationarity\n",
        "\n",
        "def stationarity_test(timeseries):\n",
        "\n",
        "    print('RESULTS OF DICKEY-FULLER TEST\\n')\n",
        "    df_test = adfuller(timeseries,autolag='AIC')\n",
        "    df_output = pd.Series(df_test[0:4], index = ['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
        "    for key, value in df_test[4].items():\n",
        "        df_output['Critical Value (%s)' %key] = value\n",
        "    print(df_output)\n",
        "    print(\"****************************************************\")\n",
        "    print(f'INFERENCE:         THE TIME SERIES IS {\"NON-\" if df_test[1]>=0.05 else \"\"}STATIONARY')\n",
        "\n",
        "stationarity_test(df)"
      ],
      "metadata": {
        "id": "sXs98q3n1LDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Make Non-stationary time series data stationary by differencing**\n",
        "\n",
        "Since from the previous results the time series is non-stationary we have to make stationary first, this is because we can not perform ARIMA models to non-stationary time series data.\n",
        "\n"
      ],
      "metadata": {
        "id": "ME3YABSZ1jVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the First Order Difference\n",
        "df_diff=df.diff().dropna()\n",
        "\n",
        "stationarity_test(train_data_diff)\n",
        "# df_diff.plot()"
      ],
      "metadata": {
        "id": "_8Ka0f0N22j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Plot ACF and PACF**"
      ],
      "metadata": {
        "id": "4vifwnn5pZwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot ACF and PACF of the stationary data this is useful in helping start to choose our model parameters (p,d,q) in our ARIMA models;\n",
        "\n",
        "\n",
        "*   P-The number of lag observations included in the AR model.\n",
        "*   D-Degree of differencing\n",
        "*   Q-Moving average of MA"
      ],
      "metadata": {
        "id": "5jxHUU7KBLPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Determine P and Q by Plotting the ACF AND PACF\n",
        "\n",
        "def plot_acf_pcf(ts_data):\n",
        "  plot_pacf(df['readig'],lags=10)\n",
        "  plot_acf(df['readig'],lags=10)\n",
        "\n",
        "plot_acf_pcf(df_diff)\n",
        "\n"
      ],
      "metadata": {
        "id": "Bauv0gjw38zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split time series data set into two : the train and test data set."
      ],
      "metadata": {
        "id": "eneMKCCYpoCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test\n",
        "train=df.iloc[:31]\n",
        "test=df.iloc[31:]"
      ],
      "metadata": {
        "id": "GqZfzTjweNvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**AR Model**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ceS21MTUqHo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit AR model of lag 3 since PACF significant spike are 3 in Number."
      ],
      "metadata": {
        "id": "NyJSSd0As2t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_diff=train.diff().dropna()\n",
        "test_diff=test.diff().dropna()\n",
        "ar_model = AutoReg(train_diff, lags=3).fit()\n",
        "print(ar_model.summary())"
      ],
      "metadata": {
        "id": "INslyGUVPeXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ch5hdciqtzuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intepretation**\n",
        "\n",
        "\n",
        "1.   The AIC is 1.447 its ideal since its small\n",
        "2.   Apart from lag 3 all other lags are significant since the p values is less that 0.05\n",
        "\n",
        "\n",
        "Using the above model lets forecast on the test data and calculate the error\n"
      ],
      "metadata": {
        "id": "tfqB9bQAtHCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start=len(train_diff)\n",
        "end=len(train_diff)+len(test)-1\n",
        "predict = ar_model.predict(start=start, end=end, dynamic=False)\n",
        "# print(predict)\n",
        "\n",
        "# Plot the prediction vs test data\n",
        "\n",
        "# pyplot.plot(pred)\n",
        "# pyplot.plot(test, color='red')\n",
        "\n",
        "predict.plot(legend=True)\n",
        "test_diff['readig'].plot(legend=True)\n",
        "# rmse=sqrt(mean_squared_error(predict,test_diff['readig']))\n",
        "# plt.title(f'The RMSE IS {rmse}')\n",
        "# print(test['readig'].mean())\n"
      ],
      "metadata": {
        "id": "vl1e0kV3P-jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Performance \n",
        "\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "rmse=sqrt(mean_squared_error(test_diff,predict))\n",
        "print(rmse)"
      ],
      "metadata": {
        "id": "iKdr0pBcQ3Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make future predictions\n",
        "\n",
        "pred_future = ar_model.predict(start=start+1, end=end+5, dynamic=False)\n",
        "print('The future predictions of the next 5 years')\n",
        "print(pred_future)\n"
      ],
      "metadata": {
        "id": "DK42rOBgRWwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# series = df[\"Number of Bookings\"]\n",
        "# new_series = np.log(series).diff()\n",
        "# # getting only the value of zeroth index since the diff() operation looses first value.\n",
        "# new_series.iloc[0] = np.log(series.iloc[0])\n",
        "# result = np.exp(new_series.cumsum())"
      ],
      "metadata": {
        "id": "J66cblEEyODN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n",
        "ar_model = AutoReg(train_data_diff, lags=3).fit()\n",
        "print(ar_model.summary())"
      ],
      "metadata": {
        "id": "Fnw7zh-tGFga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build an ARIMA model .**"
      ],
      "metadata": {
        "id": "cRCyyKJdmgU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #How to do find the optimal ARIMA model manually using Out-of-Time Cross validation\n",
        "\n",
        "# # Build Model\n",
        "# # model = ARIMA(train, order=(3,2,1))  \n",
        "# # order=(2,1,2)\n",
        "# # model=ARIMA(endog=train_data,order=order)\n",
        "\n",
        "# model=ARIMA(endog=train_data, order=(1, 1, 0))  \n",
        "# fitted = model.fit(disp=-1)  \n",
        "\n",
        "# # Forecast\n",
        "# fc, se, conf = fitted.forecast(22, alpha=0.05)  # 95% conf\n",
        "\n",
        "# # Make as pandas series\n",
        "# fc_series = pd.Series(fc, index=test_data.index)\n",
        "# lower_series = pd.Series(conf[:, 0], index=test_data.index)\n",
        "# upper_series = pd.Series(conf[:, 1], index=test_data.index)\n",
        "\n",
        "# # Plot\n",
        "# plt.figure(figsize=(12,5), dpi=100)\n",
        "# plt.plot(train_data, label='training')\n",
        "# plt.plot(test_data, label='actual')\n",
        "# plt.plot(fc_series, label='forecast')\n",
        "# plt.fill_between(lower_series.index, lower_series, upper_series, \n",
        "#                  color='k', alpha=.15)\n",
        "# plt.title('Forecast vs Actuals')\n",
        "# plt.legend(loc='upper left', fontsize=8)\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "D8PXAt7MTt2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Accuracy metrics\n",
        "# def forecast_accuracy(forecast, actual):\n",
        "#     mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
        "#     me = np.mean(forecast - actual)             # ME\n",
        "#     mae = np.mean(np.abs(forecast - actual))    # MAE\n",
        "#     mpe = np.mean((forecast - actual)/actual)   # MPE\n",
        "#     rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
        "#     corr = np.corrcoef(forecast, actual)[0,1]   # corr\n",
        "#     mins = np.amin(np.hstack([forecast[:,None], \n",
        "#                               actual[:,None]]), axis=1)\n",
        "#     maxs = np.amax(np.hstack([forecast[:,None], \n",
        "#                               actual[:,None]]), axis=1)\n",
        "#     minmax = 1 - np.mean(mins/maxs)             # minmax\n",
        "#     acf1 = acf(fc-test_data)[1]                      # ACF1\n",
        "#     return({'MAPE':mape, 'ME':me, 'MAE': mae, \n",
        "#             'MPE': mpe, 'RMSE':rmse, 'ACF1':acf1, \n",
        "#             'CORR':corr, 'MINMAX':minmax})\n",
        "\n",
        "# summary=forecast_accuracy(fc, test_data.values)\n",
        "\n",
        "# summary\n"
      ],
      "metadata": {
        "id": "1kfCx4_Ok86z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "stepwise_fit=auto_arima(df['readig'],trace=True,supprese_warnings=True)"
      ],
      "metadata": {
        "id": "bQ5A47STY2w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "import statsmodels.api as sm\n",
        "\n",
        "arima_model = sm.tsa.arima.ARIMA(train['readig'], order=(2,1,0))\n",
        "arima_model = arima_model.fit()\n",
        "arima_model.summary()\n",
        "\n",
        "# model=ARIMA(train,order=(0,1,0))\n",
        "# model=model.fit()\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "6VKqpdneZ47i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predict on Test set\n",
        "\n",
        "start=len(train)\n",
        "end=len(train)+len(test)-1\n",
        "pred=arima_model.predict(start=start,end=end,typ='levels')\n",
        "print(pred)\n",
        "# pred.index=df.index[start:end+1]"
      ],
      "metadata": {
        "id": "TEpVJYSMbiAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot predict vs Actual\n",
        "\n",
        "pred.plot(legend=True)\n",
        "test['readig'].plot(legend=True)\n",
        "rmse=sqrt(mean_squared_error(pred,test['readig']))\n",
        "plt.title(f'The RMSE IS {rmse}')\n",
        "print(test['readig'].mean())"
      ],
      "metadata": {
        "id": "_OY7Siu1dRl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the model is okay then train the model on the whole data set and make future predictions\n",
        "\n",
        "arima_model = sm.tsa.arima.ARIMA(df['readig'], order=(2,1,0))\n",
        "arima_model = arima_model.fit()\n",
        "df.tail()\n",
        "\n"
      ],
      "metadata": {
        "id": "ThjyXplPiJ35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Future Dates\n",
        "\n",
        "# index_future_dates=pd.date_range(start='2020-12-31', end ='2030-12-31')\n",
        "index_future_dates=pd.date_range(start=pd.datetime(2020, 12, 31), periods=11, freq=pd.DateOffset(years=1))\n",
        "# print(index_future_dates)\n",
        "pred2=arima_model.predict(start=len(df),end=len(df)+10,typ='levels').rename('ARIMA PREDICTIONS')\n",
        "# print(pred2)\n",
        "# pred2.index=index_future_dates\n",
        "print(pred2)\n"
      ],
      "metadata": {
        "id": "cpjwnLx8ilGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred2.plot(figsize=(10,6),legend=True)"
      ],
      "metadata": {
        "id": "FoLI-nbrmOXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Conclusion"
      ],
      "metadata": {
        "id": "bioxlfQTn04z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.machinelearningplus.com/resources/arima/arima-forecast-test-results/\n",
        "# https://www.machinelearningplus.com/resources/arima/implement-arima-model/\n",
        "# https://www.machinelearningplus.com/time-series/time-series-analysis-python/\n",
        "# https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/\n",
        "# pip install statsmodels==0.11.0\n",
        "# https://www.kaggle.com/satishgunjal/tutorial-time-series-analysis-and-forecasting\n",
        "# https://www.geeksforgeeks.org/python-arima-model-for-time-series-forecasting/"
      ],
      "metadata": {
        "id": "GbPFeUlb_2md"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}