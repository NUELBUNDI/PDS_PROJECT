{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TimeSeriesPaper.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO4I3MXYY3QF4nysCYq+Nst",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NUELBUNDI/PDS_PROJECT/blob/main/TimeSeriesPaper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Time Series Project Paper**\n",
        "\n",
        "---\n",
        "## Student Name :Lee Bundi\n",
        "## Student No:  :102586"
      ],
      "metadata": {
        "id": "zef1WYS7w-wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this paper is to model a time series analysis. \n",
        "Time series is a set of observations, each one being recorded at a specific time.\n",
        "Time series analysis is done on a time series data.\n",
        "In this paper our focus will be on univarite time series (Meaning i will use a single set of observation or variable indexed over time).\n",
        "\n",
        "The **basic objective**  is to determine a model that describes the pattern of the time series. Uses for such a model are:\n",
        "\n",
        "1. To describe the important features of the time series pattern.\n",
        "2. To explain how the past affects the future.\n",
        "3. To forecast future values of the series.\n",
        "\n",
        "\n",
        "The time series data i'm using in this paper comprise of annual average temperature in kenya for the period starting 1981 to 2020. The source of the data is https://africaopendata.org/dataset\n"
      ],
      "metadata": {
        "id": "X6FjmI_Rxuwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Steps to Time Series Analysis.\n",
        "\n",
        "\n",
        "*   Visualize the time series plot.\n",
        "*   Check for stationarity.\n",
        "*   Make the time series stationary.\n",
        "*   Plot the ACF and PCF.\n",
        "*   Select the model and train the data.\n",
        "*   Choose the best performing model.\n",
        "*   Forecast using the model choosen on the test data\n",
        "*   Analysis the Forecast performance- iterate through the step until you find the best forecast performance.\n",
        "*   Perform Future forecast.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d7KCp3b72Ezx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Packages\n",
        "\n",
        "%matplotlib inline\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh import models, palettes, transform\n",
        "from bokeh.plotting import figure, show\n",
        "import pandas as pd\n",
        "import pandas_profiling\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn import cluster, decomposition, pipeline, preprocessing\n",
        "import statsmodels\n",
        "import missingno as mn\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "import datetime\n",
        "import plotly.graph_objects as go\n",
        "from statsmodels.tsa.stattools import adfuller,acf,pacf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf ,plot_pacf\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import statsmodels.api as sm\n",
        "from pylab import rcParams\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# from pmdarima import auto_arima\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import statsmodels.api as sm\n",
        "# from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n"
      ],
      "metadata": {
        "id": "swr2Re3xw8t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the data set and load it to pandas data frame"
      ],
      "metadata": {
        "id": "y5HeqSu94s7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/NUELBUNDI/PDS_PROJECT/main/tempkenyadata.csv\",index_col=0,parse_dates=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Se9Wj5rpq4Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Plot the time series data to visualize and analysis.**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bA9MyqD75l1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(figsize=(12,6))\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Share Price for General Motors ')\n",
        "plt.title('Trend of the Time Series')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aa4R6eOJ0hTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decompose a time series.\n",
        "\n",
        "This enable us to visualize the components of time series namely:\n",
        "\n",
        "\n",
        "*   Trend-       Increasing or decreasing value in the series.\n",
        "\n",
        "*   seasonarity- Any repeating cycle\n",
        "*   Noise        Random Variation in the series\n",
        "\n",
        "*   Level       Average value in the series\n",
        "\n"
      ],
      "metadata": {
        "id": "ENn3m4mN58yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "result = seasonal_decompose(df, model='additive',freq=12)\n",
        "result.plot()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# The series as no seasonality"
      ],
      "metadata": {
        "id": "MvH2g4JP6mqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Checking For Stationarity**"
      ],
      "metadata": {
        "id": "HrMVZzix1apm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check for stationarity\n",
        "\n",
        "def stationarity_test(timeseries):\n",
        "\n",
        "    print('RESULTS OF DICKEY-FULLER TEST\\n')\n",
        "    df_test = adfuller(timeseries.iloc[:,0].values, autolag='AIC' )\n",
        "    # df_test = adfuller(timeseries,autolag='AIC')\n",
        "    df_output = pd.Series(df_test[0:4], index = ['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
        "    for key, value in df_test[4].items():\n",
        "        df_output['Critical Value (%s)' %key] = value\n",
        "    print(df_output)\n",
        "    print(\"****************************************************\")\n",
        "    print(f'INFERENCE:         THE TIME SERIES IS {\"NON-\" if df_test[1]>=0.05 else \"\"}STATIONARY')\n",
        "\n",
        "stationarity_test(df)"
      ],
      "metadata": {
        "id": "sXs98q3n1LDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Make Non-stationary time series data stationary by differencing**\n",
        "\n",
        "Since from the previous results the time series is non-stationary we have to make stationary first, this is because we can not perform ARIMA models to non-stationary time series data.\n",
        "\n"
      ],
      "metadata": {
        "id": "ME3YABSZ1jVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the First Order Difference\n",
        "df_diff=df.diff().dropna()\n",
        "\n",
        "stationarity_test(df_diff)\n",
        "# df_diff.plot()"
      ],
      "metadata": {
        "id": "_8Ka0f0N22j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Plot ACF and PACF**"
      ],
      "metadata": {
        "id": "4vifwnn5pZwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot ACF and PACF of the stationary data this is useful in helping start to choose our model parameters (p,d,q) in our ARIMA models;\n",
        "\n",
        "\n",
        "*   P-The number of lag observations included in the AR model.\n",
        "*   D-Degree of differencing\n",
        "*   Q-Moving average of MA"
      ],
      "metadata": {
        "id": "5jxHUU7KBLPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Determine P and Q by Plotting the ACF AND PACF\n",
        "\n",
        "def plot_acf_pcf(ts_data):\n",
        "  plot_pacf(df['readig'],lags=10)\n",
        "  plot_acf(df['readig'],lags=10)\n",
        "\n",
        "plot_acf_pcf(df_diff)\n",
        "\n"
      ],
      "metadata": {
        "id": "Bauv0gjw38zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split time series data set into two : the train and test data set."
      ],
      "metadata": {
        "id": "eneMKCCYpoCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Emni8qdxKhf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test\n",
        "train=df.iloc[:30]\n",
        "test=df.iloc[30:]"
      ],
      "metadata": {
        "id": "GqZfzTjweNvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build an ARIMA model .**"
      ],
      "metadata": {
        "id": "cRCyyKJdmgU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform auto-ARIMA to choice the best performing combination of (PDQ) parameters checking the one with the least AIC."
      ],
      "metadata": {
        "id": "4_dCj5ISxVuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we fit the data set into the best model chosen above."
      ],
      "metadata": {
        "id": "D9mGT41Ux0qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pmdarima as pmd\n",
        "\n",
        "def arimamodel(timeseriesarray):\n",
        "    autoarima_model = pmd.auto_arima(timeseriesarray, \n",
        "                              start_p=1, \n",
        "                              start_q=1,\n",
        "                              test=\"adf\",\n",
        "                              trace=True)\n",
        "    return autoarima_model\n",
        "\n",
        "    \n",
        "arima_model = arimamodel(train)\n",
        "arima_model.summary()"
      ],
      "metadata": {
        "id": "rKYIWKppKt0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our rest above the AIC is relatively small at 13.585 Next step is to make prediction on range of the test data and compare with the actual test data."
      ],
      "metadata": {
        "id": "PFfXj7shyL-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predict on Test data\n",
        "\n",
        "start=len(train)\n",
        "end=len(train)+len(test)-1\n",
        "pred=arima_model.predict(start=start,end=end,typ='levels')\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "TEpVJYSMbiAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot predict vs Actual\n",
        "\n",
        "# pred.plot(legend=True)\n",
        "test['readig'].plot(legend=True)\n",
        "rmse=sqrt(mean_squared_error(pred,test['readig']))\n",
        "plt.title(f'The RMSE IS {rmse}')\n",
        "print(test['readig'].mean())"
      ],
      "metadata": {
        "id": "_OY7Siu1dRl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Perfomance error\n",
        "\n",
        "rmse=sqrt(mean_squared_error(pred,test['readig']))\n",
        "print(rmse)\n"
      ],
      "metadata": {
        "id": "gxytV9vHzLpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSE IS 0.215 this is actually a good model , now we can fit our whole data into the model and do future predictions."
      ],
      "metadata": {
        "id": "tPaEAg9Gyvh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If the model is okay then train the model on the whole data set and make future predictions\n",
        "\n",
        "arima_model = sm.tsa.ARIMA(df['readig'], order=(4,2,0))\n",
        "arima_model = arima_model.fit()\n",
        "df.tail()\n",
        "\n"
      ],
      "metadata": {
        "id": "ThjyXplPiJ35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Future Dates\n",
        "\n",
        "# index_future_dates=pd.date_range(start='2020-12-31', end ='2030-12-31')\n",
        "index_future_dates=pd.date_range(start=pd.datetime(2020, 12, 31), periods=11, freq=pd.DateOffset(years=1))\n",
        "# print(index_future_dates)\n",
        "pred2=arima_model.predict(start=len(df),end=len(df)+10,typ='levels').rename('ARIMA PREDICTIONS')\n",
        "# print(pred2)\n",
        "# pred2.index=index_future_dates\n",
        "print(pred2)\n"
      ],
      "metadata": {
        "id": "cpjwnLx8ilGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred2.plot(figsize=(10,6),legend=True)"
      ],
      "metadata": {
        "id": "FoLI-nbrmOXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###References"
      ],
      "metadata": {
        "id": "bioxlfQTn04z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.machinelearningplus.com/resources/arima/arima-forecast-test-results/\n",
        "# https://www.machinelearningplus.com/resources/arima/implement-arima-model/\n",
        "# https://www.machinelearningplus.com/time-series/time-series-analysis-python/\n",
        "# https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/\n",
        "pip install statsmodels==0.11.0\n",
        "# https://www.kaggle.com/satishgunjal/tutorial-time-series-analysis-and-forecasting\n",
        "# https://www.geeksforgeeks.org/python-arima-model-for-time-series-forecasting/"
      ],
      "metadata": {
        "id": "GbPFeUlb_2md"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}